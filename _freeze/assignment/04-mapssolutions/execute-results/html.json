{
  "hash": "c54ec9be347fd9745de50a23e4ac8a8f",
  "result": {
    "markdown": "---\ntitle: \"Assignment 4 Solutions: Predicates and Measures\"\n---\n\n\n<span style=\"color:#9F281A;\">1. Load the `cejst_nw.shp` use the correct predicates to determine whether the geometries are valid and to check for empty geometries. If there are empty geometries, determine which rows have empty geometries (show your code). </span>\n\n> Remember that `predicates` return logical (i.e. TRUE or FALSE) answers so we are looking for functions with `st_is_*` to look for valid or empty geometries.  We wrap those in the `all()` or `any()` function calls so that we get a single TRUE or FALSE for the entire geometry collection rather than returning the value for each individual observation. While those can be useful for figuring out if the entire dataset meets our criteria (i.e., all are valid or any have empty geometries), identifying which records have empty geometries takes an additional step. We use `which()` to return the row index of each record that returns a TRUE for `st_is_empty()` and then subset the original data using the `[]` notation keeping only the rows with empty geometries and all other columns.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(terra)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nterra 1.7.39\n\nAttaching package: 'terra'\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n```\n:::\n\n```{.r .cell-code}\ncejst.nw <- read_sf(\"data/opt/data/2023/assignment04/cejst_nw.shp\")\nall(st_is_valid(cejst.nw))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\nany(st_is_empty(cejst.nw))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\nwhich(st_is_empty(cejst.nw))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  787  891  894  895  911  916  971 1213 1252 1708 1709 1898 2097 2106 2107\n[16] 2321 2322 2324 2423\n```\n:::\n\n```{.r .cell-code}\ncejst.nw[which(st_is_empty(cejst.nw)),]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSimple feature collection with 19 features and 123 fields (with 19 geometries empty)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nGeodetic CRS:  WGS 84\n# A tibble: 19 × 124\n   GEOID10   SF    CF    DF_PFS AF_PFS HDF_PFS DSF_PFS EBF_PFS EALR_PFS EBLR_PFS\n   <chr>     <chr> <chr>  <dbl>  <dbl>   <dbl>   <dbl>   <dbl>    <dbl>    <dbl>\n 1 41057990… Oreg… Till…     NA     NA      NA      NA      NA       NA       NA\n 2 41007990… Oreg… Clat…     NA     NA      NA      NA      NA       NA       NA\n 3 41011990… Oreg… Coos…     NA     NA      NA      NA      NA       NA       NA\n 4 41015990… Oreg… Curr…     NA     NA      NA      NA      NA       NA       NA\n 5 41039990… Oreg… Lane…     NA     NA      NA      NA      NA       NA       NA\n 6 41041990… Oreg… Linc…     NA     NA      NA      NA      NA       NA       NA\n 7 41019990… Oreg… Doug…     NA     NA      NA      NA      NA       NA       NA\n 8 53055990… Wash… San …     NA     NA      NA      NA      NA       NA       NA\n 9 53067990… Wash… Thur…     NA     NA      NA      NA      NA       NA       NA\n10 53061990… Wash… Snoh…     NA     NA      NA      NA      NA       NA       NA\n11 53061990… Wash… Snoh…     NA     NA      NA      NA      NA       NA       NA\n12 53057990… Wash… Skag…     NA     NA      NA      NA      NA       NA       NA\n13 53033990… Wash… King…     NA     NA      NA      NA      NA       NA       NA\n14 53035990… Wash… Kits…     NA     NA      NA      NA      NA       NA       NA\n15 53049990… Wash… Paci…     NA     NA      NA      NA      NA       NA       NA\n16 53027990… Wash… Gray…     NA     NA      NA      NA      NA       NA       NA\n17 53029992… Wash… Isla…     NA     NA      NA      NA      NA       NA       NA\n18 53031990… Wash… Jeff…     NA     NA      NA      NA      NA       NA       NA\n19 53009990… Wash… Clal…     NA     NA      NA      NA      NA       NA       NA\n# ℹ 114 more variables: EPLR_PFS <dbl>, HBF_PFS <dbl>, LLEF_PFS <dbl>,\n#   LIF_PFS <dbl>, LMI_PFS <dbl>, PM25F_PFS <dbl>, HSEF <dbl>, P100_PFS <dbl>,\n#   P200_I_PFS <dbl>, AJDLI_ET <int>, LPF_PFS <dbl>, KP_PFS <dbl>,\n#   NPL_PFS <dbl>, RMP_PFS <dbl>, TSDF_PFS <dbl>, TPF <dbl>, TF_PFS <dbl>,\n#   UF_PFS <dbl>, WF_PFS <dbl>, UST_PFS <dbl>, N_WTR <int>, N_WKFC <int>,\n#   N_CLT <int>, N_ENY <int>, N_TRN <int>, N_HSG <int>, N_PLN <int>,\n#   N_HLTH <int>, SN_C <int>, SN_T <chr>, DLI <int>, ALI <int>, PLHSE <int>, …\n```\n:::\n:::\n\n\n<span style=\"color:#9F281A;\"> 2. Load the `landmarks_ID.csv` table and convert it to an `sf` object. Now filter to just the hospital records (`MTFCC == \"K1231\"`) and calculate the distance between all of the hospitals in Idaho. Note that you'll have to figure out the CRS for the landmarks dataset... </span>\n\n> Here we are interested in distance which is a measure (not a predicate or transformer), but to get there we need to take a few extra steps. First, we read in the `csv` file and convert it to coordinates (using `st_as_sf`, a transformer). Then we use `dplyr::filter` to retain only the hospitals in the dataset. Finally, because this is a lat/long dataset, we assume a geodetic projection of WGS84 and assign it to the filtered object. Once we've gotten all that squared away, it's just a matter of using the `st_distance` function to return the distance matrix for all objects in the dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhospitals.id <- read_csv(\"data/opt/data/2023/assignment04/landmarks_ID.csv\") %>% \n  st_as_sf(., coords = c(\"longitude\", \"lattitude\")) %>% \n  filter(., MTFCC == \"K1231\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 12169 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): ANSICODE, FULLNAME, MTFCC\ndbl (4): STATEFP, POINTID, longitude, lattitude\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nst_crs(hospitals.id) <- 4269\n\ndist.hospital <- st_distance(hospitals.id)\n\ndist.hospital[1:5, 1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUnits: [m]\n          [,1]      [,2]     [,3]     [,4]     [,5]\n[1,]      0.00  61303.25 186961.5 480013.6 538397.3\n[2,]  61303.25      0.00 134425.2 492433.2 547734.4\n[3,] 186961.47 134425.16      0.0 459255.9 505156.4\n[4,] 480013.57 492433.21 459255.9      0.0  62690.4\n[5,] 538397.34 547734.35 505156.4  62690.4      0.0\n```\n:::\n:::\n\n\n\n<span style=\"color:#9F281A;\"> 3. Filter the `cejst_nw.shp` to just those records from Ada County. Then filter again to return the row with the highest annual loss rate for agriculture (2 hints: you'll need to look at the `columns.csv` file in the data folder to figure out which column is the expected agricultural loss rate and you'll need to set `na.rm=TRUE`when looking for the maximum value). Calculate the area of the resulting polygon.</span>\n\n>This one should be relatively straightforward. We start with another call to `dplyr::filter` to get down to just the tracts in Ada County (note the use of the `&` to combine two logical calls). Then we use a second filter to return the row with the `max` value for agricultural loss. Note that we have to use the `na.rm=TRUE` argument to avoid having the `NA` values force the function to return `NA`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nada.cejst <- cejst.nw %>% \n  filter(., SF == \"Idaho\" & CF == \"Ada County\") \n\nada.max.EALR <- ada.cejst %>%  \n  filter(., EALR_PFS == max(EALR_PFS, na.rm = TRUE))\n  \nada.max.EALR[, c(\"SF\", \"CF\", \"EALR_PFS\")]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSimple feature collection with 1 feature and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -116.1998 ymin: 43.11297 xmax: -115.9742 ymax: 43.59134\nGeodetic CRS:  WGS 84\n# A tibble: 1 × 4\n  SF    CF         EALR_PFS                                             geometry\n  <chr> <chr>         <dbl>                                   <MULTIPOLYGON [°]>\n1 Idaho Ada County      0.7 (((-116.1371 43.55217, -116.137 43.55222, -116.1369…\n```\n:::\n:::\n\n\n<span style=\"color:#9F281A;\"> 4. Finally, look at the helpfile for the `terra::adjacent` command. How do you specify which cells you'd like to get the adjacency matrix for? How do you return only the cells touching your cells of interest? Use the example in the helpfile to illustrate how you'd do this on a toy dataset - this will help you learn to ask minimally reproducible examples.</span>\n\n> We can access the helpfile for `adjacent` by using `?terra::adjacent` (I won't do that here because I don't want to print the entire helpfile). From that we can see that the `cells` argument is the place to specify which cells we are interested in. also see that the `directions` argument allows us to specify whether we want \"rook\", \"bishop\", or \"queen\" neighbors. Finally, we see that if we want to exclude the focal cell itself, we have to set `include` to FALSE. By plotting the map with the cell numbers, we can see that cells 1 and 5 are on th top row of the raster and thus do not have any neighbors for for the upper 3 categories whereas cell 55 hase all 8 neighbors. If you choose cells that are in the center of the raster, you get all neighbors\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr <- rast(nrows=10, ncols=10)\ncellnum <- cells(r)\nr[] <- cellnum\nplot(r)\n```\n\n::: {.cell-output-display}\n![](04-mapssolutions_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nadjacent(r, cells=c(1, 5, 55), directions=\"queen\", include=FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n0   NaN  NaN  NaN   10    2   20   11   12\n4   NaN  NaN  NaN    4    6   14   15   16\n54   44   45   46   54   56   64   65   66\n```\n:::\n\n```{.r .cell-code}\nadjacent(r, cells=c(51, 52, 55), directions=\"queen\", include=FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n50   50   41   42   60   52   70   61   62\n51   41   42   43   51   53   61   62   63\n54   44   45   46   54   56   64   65   66\n```\n:::\n:::\n",
    "supporting": [
      "04-mapssolutions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}