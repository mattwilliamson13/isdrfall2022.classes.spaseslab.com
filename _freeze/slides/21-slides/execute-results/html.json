{
  "hash": "5d7582a449c81ccc18b63a62e4fb7686",
  "result": {
    "markdown": "---\ntitle: \"Multivariate Analysis III\"\nsubtitle: \"HES 505 Fall 2022: Session 21\"\nauthor: \"Matt Williamson\"\nexecute: \n  eval: false\nformat: \n  revealjs:\n    theme: mytheme.scss\n    slide-number: true\n    show-slide-number: print\n    self-contained: true  \n---\n\n\n\n\n# Objectives {background=\"#0033A0\"}\n\nBy the end of today you should be able to:\n\n- Articulate three different reasons for modeling and how they link to assessments of fit\n\n- Describe and implement several test statistics for assessing model fit\n\n- Describe and implement several assessments of classification\n\n- Describe and implement resampling techniques to estimate predictive performance\n\n# The 3 Faces of Models {background=\"#0033A0\"}\n\n## Best Model for What?\n\n::: columns\n::: {.column width=\"50%\"}\n![from Tradennick et al. 2021](img/slide_21/Tredennick.png)\n:::\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 0.7em\"}\n* __Exploration:__ describe patterns in the data and generate hypotheses\n\n* __Inference:__ evaluate the strength of evidence for some statement about the process\n\n* __Prediction:__ forecast outcomes at unsampled locations based on covariates\n:::\n:::\n:::\n\n## The Importance of Model Fit\n\n* The general regression context:\n\n$$\n\\begin{equation}\n\\hat{y} = \\mathbf{X}\\hat{\\beta}\n\\end{equation}\n$$\n\n* __Inference__ is focused on robust estimates of $\\hat{\\beta}$ given the data we have\n\n* __Prediction__ is focused on accurate forecasts of $\\hat{y}$ at locations where we have yet to collect the data\n\n## Inference and Presence/Absence Data\n\n* $\\hat{\\beta}$ is conditional on variables in the model __and__ those not in the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnsamp <- 1000\ndf <- data.frame(x1 = rnorm(nsamp,0,1),\n                 x2 = rnorm(nsamp,0,1),\n                 x3 = rnorm(nsamp,0,1))\n\nlinpred <- 1 + 2*df$x1 -0.18*df$x2 -3.5*df$x3\ny <- rbinom(nsamp, 1, plogis(linpred))\ndf <- cbind(df, y)\n\nmod1 <- glm(y~x1 +x2, data=df, family=\"binomial\")\nmod2 <- glm(y~x1 +x2 + x3, data=df, family=\"binomial\")\n```\n:::\n\n\n## Inference \\& Presence/Absence Data\n\n::: columns\n::: {.column width=\"40%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(mod1)\ncoef(mod2)\n```\n:::\n\n:::\n:::{.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nprd1 <- predict(mod1, df, \"response\")\ndif1 <- plogis(linpred) - prd1\nprd2 <- predict(mod2, df, \"response\")\ndif2 <- plogis(linpred) - prd2\n```\n:::\n\n::: {.cell}\n\n:::\n\n:::\n:::\n\n> Inferring coefficient effects requires that your model fit the data well\n\n# Assessing Model Fit {background=\"#0033A0\"}\n\n## \n\n\n::: {.cell}\n\n:::\n\n\n## Using Test Statistics\n\n::: columns\n::: {.column width=\"40%\"}\n* $R^2$ for linear regression:\n\n$$\n\\begin{equation}\nR^2 = 1- \\frac{SS_{res}}{SS_{tot}}\\\\\nSS_{res} = \\sum_{i}(y_i- f_i)^2\\\\\nSS_{tot} = \\sum_{i}(y_i-\\bar{y})^2\n\\end{equation}\n$$\n:::\n::: {.column width=\"60%\"}\n* Perfect prediction ($f_i = y_i$); $SS_{res} = 0$; and $R^2 = 1$\n\n* Null prediction (Intercept only) ($f_i = \\bar{y}$); $SS_{res} = SS_{tot}$; and $R^2 = 0$\n\n* No direct way of implementing for logistic regression\n:::\n:::\n\n## Pseudo- $R^2$\n\n::: columns\n::: {.column width=\"40%\"}\n$$\n\\begin{equation}\nR^2_L = \\frac{D_{null} - D_{fitted}}{D_{null}}\n\\end{equation}\n$$\n:::\n::: {.column width=\"60%\"}\n* Cohen's Likelihood Ratio\n\n* Deviance ($D$), the difference between the model and some hypothetical perfect model (lower is better)\n\n* Challenge: Not monotonically related to $p$\n\n* Challenge: How high is too high?\n:::\n:::\n\n## Cohen's Likelihood Ratio \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogistic.rich <- glm(y ~ MeanAnnTemp + PrecipWetQuarter + PrecipDryQuarter, \n                     family=binomial(link=\"logit\"),\n                     data=pts.df[,2:8])\n\nwith(logistic.rich, \n     null.deviance - deviance)/with(logistic.rich,\n                                    null.deviance)\n```\n:::\n\n\n## Pseudo- $R^2$\n\n::: columns\n::: {.column width=\"50%\"}\n\n$$\n\\begin{equation}\n\\begin{aligned}\nR^2_{CS} &= 1 - \\left( \\frac{L_0}{L_M} \\right)^{(2/n)}\\\\\n &= 1 - \\exp^{2(ln(L_0)-ln(L_M))/n}\n\\end{aligned}\n\\end{equation}\n$$\n:::\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 0.7em\"}\n* Cox and Snell $R^2$\n\n* Likelihood ($L$), the probability of observing the sample given an assumed distribution\n\n* Challenge: Maximum value is less than 1 and changes with $n$\n\n* Correction by Nagelkerke so that maximum is 1\n:::\n:::\n:::\n\n## Cox and Snell $R^2$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogistic.null <- glm(y ~ 1, \n                     family=binomial(link=\"logit\"),\n                     data=pts.df[,2:8])\n\n1 - exp(2*(logLik(logistic.null)[1] - logLik(logistic.rich)[1])/nobs(logistic.rich))\n```\n:::\n\n\n\n## Using Test Statistics\n\n* Based on the data used in the model (i.e., not prediction)\n\n* Likelihood Ratio behaves most similarly to $R^2$\n\n* Cox and Snell (and Nagelkerke) increases with more presences\n\n* Ongoing debate over which is \"best\"\n\n* __Don't defer to a single statistic__\n\n# Assessing Predictive Ability {background=\"#0033A0\"}\n\n## Predictive Performance and Fit\n\n* Predictive performance can be an estimate of fit\n\n* Comparisons are often relative (better $\\neq$ good)\n\n* Theoretical and subsampling methods\n\n## Theoretical Assessment of Predictive Performance\n\n::: columns\n::: {.column width=\"40%\"}\n![Hirotugu Akaike of AIC](img/slide_21/Akaike.jpg)\n\n\n:::\n::: {.column width=\"60%\"}\n::: {style=\"font-size: 0.7em\"}\n* Information Criterion Methods\n\n* Minimize the amount of information lost by using model to approximate true process\n\n* Trade-off between fit and overfitting\n\n* Can't know the true process (so comparisons are relative)\n$$\n\\begin{equation}\nAIC = -2ln(\\hat{L}) +2k\n\\end{equation}\n$$\n:::\n:::\n:::\n\n## AIC Comparison\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogistic.null <- glm(y ~ 1, \n                     family=binomial(link=\"logit\"),\n                     data=pts.df[,2:8])\n\nlogistic.rich <- glm(y ~ MeanAnnTemp + PrecipWetQuarter + PrecipDryQuarter, \n                     family=binomial(link=\"logit\"),\n                     data=pts.df[,2:8])\n\nAIC(logistic.null, logistic.rich)\n```\n:::\n\n\n## Sub-sampling Methods\n\n::: columns\n::: {.column width=\"60%\"}\n* Split data into _training_ and _testing_\n\n* Testing set needs to be large enough for results to be statistically meaningful\n\n* Test set should be representative of the data as a whole\n\n* Validation data used to tune parameters (not always)\n:::\n::: {.column width=\"40%\"}\n![](img/slide_21/itest.png)\n:::\n:::\n\n## Subsampling your data with `caret`\n\n::: {.cell}\n\n```{.r .cell-code}\npts.df$y <- as.factor(ifelse(pts.df$y == 1, \"Yes\", \"No\"))\nlibrary(caret)\nTrain <- createDataPartition(pts.df$y, p=0.6, list=FALSE)\n\ntraining <- pts.df[ Train, ]\ntesting <- pts.df[ -Train, ]\n```\n:::\n\n\n## Misclassification\n\n::: columns\n::: {.column width=\"60%\"}\n* Confusion matrices compare actual values to predictions\n\n::: {style=\"font-size: 0.7em\"}\n* True Positive (TN) - This is correctly classified as the class if interest / target.\n* True Negative (TN) - This is correctly classified as not a class of interest / target.\n* False Positive (FP) - This is wrongly classified as the class of interest / target.\n* False Negative (FN) - This is wrongly classified as not a class of interest / target.\n:::\n:::\n::: {.column width=\"40%\"}\n![](img/slide_21/confmatrix.png)\n:::\n:::\n\n## Confusion Matrices in R\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain.log <- glm(y ~ ., \n                 family=\"binomial\", \n                 data=training[,2:8])\n\npredicted.log <- predict(train.log, \n                         newdata=testing[,2:8], \n                         type=\"response\")\n\npred <- as.factor(\n  ifelse(predicted.log > 0.5, \n                         \"Yes\",\n                         \"No\"))\n```\n:::\n\n:::\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 0.7em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nconfusionMatrix(testing$y, pred)\n```\n:::\n\n:::\n:::\n:::\n\n## Confusion Matrices\n\n::: columns\n::: {.column width=\"70%\"}\n$$\n\\begin{equation}\n\\begin{aligned}\nAccuracy &= \\frac{TP + TN}{TP + TN + FP + FN}\\\\\nSensitivity &= \\frac{TP}{TP + FN}\\\\\nSpecificity &= \\frac{TN}{FP + TN}\\\\\nPrecision &= \\frac{TP}{TP + FP}\\\\\nRecall &= \\frac{TP}{TP + FN}\n\\end{aligned}\n\\end{equation}\n$$\n:::\n::: {.column width=\"30%\"}\n:::{style=\"text-align: middle;\"}\n **Depends upon threshold!!**\n:::\n:::\n:::\n\n## Confusion Matrices in R\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tree)\ntree.model <- tree(y ~ . , training[,2:8])\npredict.tree <- predict(tree.model, newdata=testing[,2:8], type=\"class\")\n```\n:::\n\n:::\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 0.7em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nconfusionMatrix(testing$y, predict.tree)\n```\n:::\n\n:::\n:::\n:::\n\n## Confusion Matrices in R\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(randomForest)\nclass.model <- y ~ .\nrf <- randomForest(class.model, data=training[,2:8])\npredict.rf <- predict(rf, newdata=testing[,2:8], type=\"class\")\n```\n:::\n\n:::\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 0.7em\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nconfusionMatrix(testing$y, predict.rf)\n```\n:::\n\n:::\n:::\n:::\n\n## Threshold-Free Methods\n\n::: columns\n::: {.column width=\"40%\"}\n![](img/slide_21/roc.png)\n:::\n::: {.column width=\"60%\"}\n\n* Receiver Operating Characteristic Curves\n\n* Illustrates discrimination of binary classifier as the threshold is varied\n\n* Area Under the Curve (AUC) provides an estimate of classification ability\n:::\n:::\n\n## Criticisms of ROC/AUC\n\n* Treats false positives and false negatives equally\n\n* Undervalues models that predict across smaller geographies\n\n* Focus on _discrimination_ and not _calibration_\n\n* New methods for presence-only data\n\n## ROC in R\n\n# Cross-validation\n\n# Spatial predictions...\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}