{
  "hash": "2e711c9cad5171ed3654cd042f98aee2",
  "result": {
    "markdown": "---\ntitle: \"Interpolation and Autocorrelation\"\nsubtitle: \"HES 505 Fall 2022: Session 17\"\nauthor: \"Matt Williamson\"\nformat: \n  revealjs:\n    theme: mytheme.scss\n    slide-number: true\n    show-slide-number: print\n    self-contained: true  \n---\n\n\n\n\n# Objectives {background=\"#0033A0\"}\n\nBy the end of today you should be able to:\n\n- Distinguish deterministic and stochastic processes\n\n- Define autocorrelation and describe its estimation\n\n- Articulate the benefits and drawbacks of autocorrelation\n\n- Leverage point patterns and autocorrelation to interpolate missing data\n\n## Description vs. process?\n\n::: columns\n::: {.column width=\"60%\"}\n\n* Vizualization and the detection of patterns\n\n* The challenge of geographic data\n\n* Implications for analysis \n:::\n::: {.column width=\"40%\"}\n![Inequality in the United States: Quintiles of Gini Index by County: 2006–2010. The greater the Gini index, the more unequal a county’s income distribution is.](img/slide_17/gini-map-census.png)\n:::\n:::\n\n\n## Patterns as realizations of spatial processes\n\n* A __spatial process__ is a description of how a spatial pattern might be _generated_\n\n* __Generative models__ \n\n* An observed pattern as a _possible realization_ of an hypothesized process\n\n## Deterministic vs. stochastic processes\n\n::: columns\n::: {.column width=\"70%\"}\n* Deterministic processes: always produces the same outcome\n\n$$\nz = 2x + 3y\n$$\n\n* Results in a spatially continuous field\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- rast(nrows = 10, ncols=10, xmin = 0, xmax=10, ymin = 0, ymax=10)\nvalues(x) <- 1\nz <- x\nvalues(z) <- 2 * crds(x)[,1] + 3*crds(x)[,2]\n```\n:::\n\n\n:::\n::: {.column width=\"30%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-slides_files/figure-revealjs/unnamed-chunk-3-1.png){width=480}\n:::\n:::\n\n:::\n:::\n\n## Deterministic vs. stochastic processes\n\n::: columns\n::: {.column width=\"40%\"}\n::: {style=\"font-size: 0.7em\"}\n* Stochastic processes: variation makes each realization difficult to predict\n\n$$\nz = 2x + 3y + d\n$$\n\n* The _process_ is random, not the result (!!)\n* Measurement error makes deterministic processes appear stochastic\n:::\n:::\n::: {.column width=\"60%\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- rast(nrows = 10, ncols=10, xmin = 0, xmax=10, ymin = 0, ymax=10)\nvalues(x) <- 1\nfun <- function(z){\na <- z\nd <- runif(ncell(z), -50,50)\nvalues(a) <- 2 * crds(x)[,1] + 3*crds(x)[,2] + d\nreturn(a)\n}\n\nb <- replicate(n=6, fun(z=x), simplify=FALSE)\nd <- do.call(c, b)\n```\n:::\n\n:::\n:::\n\n## Deterministic vs. stochastic processes\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-slides_files/figure-revealjs/stocproc2-1.png){width=960}\n:::\n:::\n\n\n## Expected values and hypothesis testing\n\n::: columns\n::: {.column width=\"60%\"}\n::: {style=\"font-size: 0.7em\"}\n\n* Considering each outcome as the realization of a process allows us to generate expected values\n\n* The simplest spatial process is Completely Spatial Random (CSR) process\n\n* __First Order__ effects: any event has an equal probability of occurring in a location\n\n* __Second Order__ effects: the location of one event is independent of the other events\n:::\n:::\n::: {.column width=\"40%\"}\n![From Manuel Gimond](img/slide_17/IRP_CSR.png)\n:::\n:::\n\n## Generating expectations for CSR\n\n::: columns\n::: {.column width=\"40%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-slides_files/figure-revealjs/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n:::\n::: {.column width=\"60%\"}\n::: {style=\"font-size: 0.7em\"}\n* We can use quadrat counts to estimate the expected number of events in a given area\n\n* The probability of each possible count is given by:\n\n$$\nP(n,k) = {n \\choose x}p^k(1-p)^{n-k}\n$$\n\n* Given total coverage of quadrats, then $p=\\frac{\\frac{a}{x}}{a}$ and\n\n$$\n\\begin{equation}\nP(k,n,x) = {n \\choose k}\\bigg(\\frac{1}{x}\\bigg)^k\\bigg(\\frac{x-1}{x}\\bigg)^{n-k}\n\\end{equation}\n$$\n:::   \n:::\n:::\n\n\n# Tobler's Law\n\n> ‘everything is usually related to all else but those which are near to each other\n>are more related when compared to those that are further away’.\n> <footer>Waldo Tobler</footer>\n\n\n---\n## Spatial autocorrelation\n\n![From Manuel Gimond](img/slide_17/Random_maps.png)\n \n## (One) Measure of autocorrelation\n\n::: columns\n::: {.column width=\"50%\"}\n* Moran's I\n\n![](img/slide_17/MI.png)\n:::\n::: {.column width=\"50%\"}\n\n![](img/slide_17/mI2.png)\n:::\n:::\n\n## Moran's I: An example\n\n::: columns\n::: {.column width=\"60%\"}\n::: {style=\"font-size: 0.7em\"}\n\n* Use `spdep` package\n\n* Estimate neighbors\n\n* Generate weighted average\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2354)\n# Load the shapefile\ns <- readRDS(url(\"https://github.com/mgimond/Data/raw/gh-pages/Exercises/fl_hr80.rds\"))\n\n# Define the neighbors (use queen case)\nnb <- poly2nb(s, queen=TRUE)\n\n# Compute the neighboring average homicide rates\nlw <- nb2listw(nb, style=\"W\", zero.policy=TRUE)\n#estimate Moran's I\nmoran.test(s$HR80,lw, alternative=\"greater\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tMoran I test under randomisation\n\ndata:  s$HR80  \nweights: lw    \n\nMoran I statistic standard deviate = 1.8891, p-value = 0.02944\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.136277593      -0.015151515       0.006425761 \n```\n:::\n:::\n:::\n:::\n::: {.column width=\"40%\"}\n![](img/slide_17/florida.png)\n\n:::\n:::\n\n## Moran's I: An example\n::: columns\n::: {.column width=\"60%\"}\n::: {.cell}\n\n```{.r .cell-code}\nM1 <- moran.mc(s$HR80, lw, nsim=9999, alternative=\"greater\")\n\n\n\n# Display the resulting statistics\nM1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tMonte-Carlo simulation of Moran I\n\ndata:  s$HR80 \nweights: lw  \nnumber of simulations + 1: 10000 \n\nstatistic = 0.13628, observed rank = 9575, p-value = 0.0425\nalternative hypothesis: greater\n```\n:::\n:::\n\n:::\n::: {.column width=\"40%\"}\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-slides_files/figure-revealjs/unnamed-chunk-8-1.png){width=576}\n:::\n:::\n:::\n:::\n\n## The challenge of areal data\n\n* Spatial autocorrelation threatens _second order_ randomness\n\n* Areal data means an infinite number of potential distances\n\n* Neighbor matrices, $\\boldsymbol W$, allow different characterizations\n\n\n# Interpolation {background=\"#0033A0\"}\n\n## Interpolation\n\n* Goal: estimate the value of $z$ at new points in $\\mathbf{x_i}$\n\n* Most useful for continuous values\n\n* Nearest-neighbor, Inverse Distance Weighting, Kriging\n\n## Nearest neighbor\n\n* find $i$ such that $| \\mathbf{x_i} - \\mathbf{x}|$ is minimized\n\n* The estimate of $z$ is $z_i$\n\n::: columns\n::: {.column width=\"60%\"}\n::: {style=\"font-size: 0.7em\"}\n::: {.cell}\n\n```{.r .cell-code}\ndata(meuse)\nr <- rast(system.file(\"ex/meuse.tif\", package=\"terra\"))\nsfmeuse <- st_as_sf(meuse, coords = c(\"x\", \"y\"), crs=crs(r))\nnodes <- st_make_grid(sfmeuse,\n                      cellsize = 25,\n                      what = \"centers\")\n\ndist <- distance(vect(nodes), vect(sfmeuse))\nnearest <- apply(dist, 1, function(x) which(x == min(x)))\nzinc_nn <- sfmeuse$zinc[nearest]\npreds <- st_as_sf(nodes)\npreds$zn <- zinc_nn\npreds <- as(preds, \"Spatial\")\ngridded(preds) <- TRUE\npreds.rast <- rast(preds)\nr.resamp <- resample(r, preds.rast)\npreds.rast <- mask(preds.rast, r.resamp)\n```\n:::\n:::\n:::\n::: {.column width=\"40%\"}\n::: {.cell}\n::: {.cell-output-display}\n![](17-slides_files/figure-revealjs/unnamed-chunk-10-1.png){width=480}\n:::\n:::\n:::\n:::\n\n## Inverse-Distance Weighting\n\n* Weight closer observations more heavily\n\n$$\n\\begin{equation}\n\\hat{z}(\\mathbf{x}) = \\frac{\\sum_{i=1}w_iz_i}{\\sum_{i=1}w_i}\n\\end{equation}\n$$\nwhere\n\n$$\n\\begin{equation}\nw_i = | \\mathbf{x} - \\mathbf{x}_i |^{-\\alpha}\n\\end{equation}\n$$\nand $\\alpha > 0$ ($\\alpha  = 1$ is inverse; $\\alpha = 2$ is inverse square)\n\n## Inverse-Distance Weighting\n\n* `terra::interpolate` provides flexible interpolation methods\n\n* Use the `gstat` package to develop the formula\n\n::: {.cell}\n\n```{.r .cell-code}\nmgsf05 <- gstat(id = \"zinc\", formula = zinc~1, data=sfmeuse,  nmax=7, set=list(idp = 0.5))\nmgsf2 <- gstat(id = \"zinc\", formula = zinc~1, data=sfmeuse,  nmax=7, set=list(idp = 2))\ninterpolate_gstat <- function(model, x, crs, ...) {\n\tv <- st_as_sf(x, coords=c(\"x\", \"y\"), crs=crs)\n\tp <- predict(model, v, ...)\n\tas.data.frame(p)[,1:2]\n}\nzsf05 <- interpolate(r, mgsf05, debug.level=0, fun=interpolate_gstat, crs=crs(r), index=1)\nzsf2 <- interpolate(r, mgsf2, debug.level=0, fun=interpolate_gstat, crs=crs(r), index=1)\n```\n:::\n\n## Inverse-Distance Weighting\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-slides_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n## Inverse-Distance Weighting\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-slides_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n## Kriging\n::: {style=\"font-size: 0.8em\"}\n* Previous methods predict $z$ as a (weighted) function of distance\n\n* Treat the observations as perfect (no error)\n\n* If we imagine that $z$ is the outcome of some spatial process such that:\n\n$$\n\\begin{equation}\nz(\\mathbf{x}) = \\mu(\\mathbf{x}) + \\epsilon(\\mathbf{x})\n\\end{equation}\n$$\n\nthen any observed value of $z$ is some function of the process ($\\mu(\\mathbf{x})$) and some error ($\\epsilon(\\mathbf{x})$)\n\n* Kriging exploits autocorrelation in $\\epsilon(\\mathbf{x})$ to identify the trend and interpolate accordingly\n:::\n\n## Autocorrelation\n\n* __Correlation__ the tendency for two variables to be related\n\n* __Autocorrelation__ the tendency for observations that are closer (in space or time) to be correlated\n\n* __Positive autocorrelation__ neighboring observations have $\\epsilon$ with the same sign\n\n* __Negative autocorrelation__ neighboring observations have $\\epsilon$ with a different sign (rare in geography)\n\n## Ordinary Kriging\n\n* Assumes that the deterministic part of the process ($\\mu(\\mathbf{x})$) is an unknown constant ($\\mu$)\n\n$$\n\\begin{equation}\nz(\\mathbf{x}) = \\mu + \\epsilon(\\mathbf{x})\n\\end{equation}\n$$\n* Specified in call to `variogram` and `gstat` as `y~1` (or some other constant)\n\n::: {.cell}\n\n```{.r .cell-code}\nv <- variogram(log(zinc)~1, ~x+y, data=meuse)\nmv <- fit.variogram(v, vgm(1, \"Sph\", 300, 1))\ngOK <- gstat(NULL, \"log.zinc\", log(zinc)~1, meuse, locations=~x+y, model=mv)\nOK <- interpolate(r, gOK, debug.level=0)\n```\n:::\n\n## Ordinary Kriging\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-slides_files/figure-revealjs/unnamed-chunk-15-1.png){width=960}\n:::\n:::\n\n## Universal Kriging\n\n* Assumes that the deterministic part of the process ($\\mu(\\mathbf{x})$) is now a function of the location $\\mathbf{x}$\n\n* Could be the location or some other attribute\n\n* Now `y` is a function of some aspect of `x`\n\n::: {.cell}\n\n```{.r .cell-code}\nvu <- variogram(log(zinc)~elev, ~x+y, data=meuse)\nmu <- fit.variogram(vu, vgm(1, \"Sph\", 300, 1))\ngUK <- gstat(NULL, \"log.zinc\", log(zinc)~elev, meuse, locations=~x+y, model=mu)\nnames(r) <- \"elev\"\nUK <- interpolate(r, gUK, debug.level=0)\n```\n:::\n\n## Universal Kriging\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-slides_files/figure-revealjs/unnamed-chunk-17-1.png){width=960}\n:::\n:::\n\n## Universal Kriging\n\n::: {.cell}\n\n```{.r .cell-code}\nvu <- variogram(log(zinc)~x + x^2 + y + y^2, ~x+y, data=meuse)\nmu <- fit.variogram(vu, vgm(1, \"Sph\", 300, 1))\ngUK <- gstat(NULL, \"log.zinc\", log(zinc)~x + x^2 + y + y^2, meuse, locations=~x+y, model=mu)\nnames(r) <- \"elev\"\nUK <- interpolate(r, gUK, debug.level=0)\n```\n:::\n\n## Universal Kriging\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-slides_files/figure-revealjs/unnamed-chunk-19-1.png){width=960}\n:::\n:::\n\n## Co-Kriging\n\n* relies on autocorrelation in $\\epsilon_1(\\mathbf{x})$ for $z_1$ AND cross correlation with other variables ($z_{2...j}$)\n\n* Extending the ordinary kriging model gives:\n\n$$\n\\begin{equation}\nz_1(\\mathbf{x}) = \\mu_1 + \\epsilon_1(\\mathbf{x})\\\\\nz_2(\\mathbf{x}) = \\mu_2 + \\epsilon_2(\\mathbf{x})\n\\end{equation}\n$$\n* Note that there is autocorrelation within both $z_1$ and $z_2$ (because of the $\\epsilon$) and cross-correlation (because of the location, $\\mathbf{x}$)\n\n* Not required that all variables are measured at exactly the same points\n\n## Co-Kriging\n\n* Process is just a linked series of `gstat` calls\n\n::: {.cell}\n\n```{.r .cell-code}\ngCoK <- gstat(NULL, 'log.zinc', log(zinc)~1, meuse, locations=~x+y)\ngCoK <- gstat(gCoK, 'elev', elev~1, meuse, locations=~x+y)\ngCoK <- gstat(gCoK, 'cadmium', cadmium~1, meuse, locations=~x+y)\ncoV <- variogram(gCoK)\ncoV.fit <- fit.lmc(coV, gCoK, vgm(model='Sph', range=1000))\n\ncoK <- interpolate(r, coV.fit, debug.level=0)\n```\n:::\n\n## Co-Kriging\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-slides_files/figure-revealjs/unnamed-chunk-21-1.png){width=960}\n:::\n:::\n\n## Co-Kriging\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-slides_files/figure-revealjs/unnamed-chunk-22-1.png){width=960}\n:::\n:::\n\n## A Note about Semivariograms\n\n\n* __nugget__ - the proportion of semivariance that occurs at small distances\n\n* __sill__ - the maximum semivariance between pairs of observations\n\n* __range__ - the distance at which the __sill__ occurs \n\n* __experimental__ vs. __fitted__ variograms\n\n## A Note about Semivariograms\n\n![](img/slide_16/index.png)\n\n\n## Fitted Semivariograms\n\n* Rely on functional forms to model semivariance\n\n![](img/slide_16/Variogram-models.png)\n\n",
    "supporting": [
      "17-slides_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}